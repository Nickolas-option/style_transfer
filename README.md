# LEGO Style Transfer with JoJoGAN

## Overview

This repository contains an end-to-end pipeline for fine-tuning a StyleGAN-based model using JoJoGAN for LEGO-style image transformation. The project includes data preprocessing, synthetic data generation, and training scripts.

## Features

Face Detection & Preprocessing: Utilizes FaceNet-PyTorch for facial detection and alignment.

Synthetic Data Generation: Uses yandex-art API to generate LEGO-style face images.

JoJoGAN for Style Transfer: Implements JoJoGAN [arXiv:2112.11641](https://arxiv.org/abs/2112.11641) for fine-tuning StyleGAN with minimal training data.

Evaluation Metrics: Supports FID, LPIPS, and Inception Score evaluation. **(TBA)**


## Dataset Preparation

We used both real and synthetic data to enhance model performance. Synthetic images (~150) were generated using yandex-art.

Face Detection: Removing incorrectly formatted or obscured faces using MTCNN.

Embedding Filtering: Sorting detected faces by similarity to an average face embedding to ensure high-quality samples.



# ğŸ—ï¸ Project Structure  

This repository is structured to efficiently handle **style transfer** using **StyleGAN** and **JoJoGAN**, incorporating data preprocessing, synthetic data generation, and training pipelines.  

## ğŸ“‚ Directory Overview  

  ```plaintext
style_transfer/
â”‚
â”œâ”€â”€ .git/                     # Git repository metadata
â”œâ”€â”€ .gitignore                # Specifies intentionally untracked files that Git should ignore
â”œâ”€â”€ .pylintrc                 # Pylint configuration file
â”œâ”€â”€ .ruff_cache/              # Cache directory for Ruff linter/formatter
â”œâ”€â”€ .venv/                    # Virtual environment directory
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ notebooks/
â”‚   â”‚   â””â”€â”€ collected_data_eda.ipynb # (Assuming this file exists based on original structure)
â”‚   â”œâ”€â”€ preprocessing/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ prepare_dataset.py # Script to prepare the dataset
â”‚   â”‚   â””â”€â”€ utils/
â”‚   â”‚       â”œâ”€â”€ __init__.py
â”‚   â”‚       â”œâ”€â”€ collection_utils.py # Utilities for data collection
â”‚   â”‚       â””â”€â”€ face_detector.py    # Face detection utility
â”‚   â”œâ”€â”€ scripts/
â”‚   â”‚   â”œâ”€â”€ readme.md               # README for data scripts
â”‚   â”‚   â”œâ”€â”€ scrapping_lego_script.py # LEGO-style image scraping script
â”‚   â”‚   â””â”€â”€ synth_gen.py          # Synthetic data generation script
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ image_dataset.py      # Custom image dataset class
â”‚
â”œâ”€â”€ README.md                 # Project README file
â”œâ”€â”€ requirements.txt          # Python package dependencies
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ stylegan/
â”‚       â””â”€â”€ training/
â”‚           â””â”€â”€ train.py          # Main StyleGAN training script
â”‚
â””â”€â”€ test_input/               # Directory for test inputs
```

## Setup

1.  **Clone the repository:**
    ```bash
    git clone https://github.com/Nickolas-option/style_transfer
    cd style_transfer
    ```

2.  **Create and activate a virtual environment:**
    ```bash
    python3 -m venv .venv
    source .venv/bin/activate  # On Windows use `.venv\Scripts\activate`
    ```

3.  **Install dependencies:**
    ```bash
    pip install -r requirements.txt
    ```

## Running the Project

The main training script is located at `scripts/stylegan/training/train.py`.

1.  **Ensure the virtual environment is active:**
    ```bash
    source .venv/bin/activate
    ```

2.  **Run the training script:**
    ```bash
    python scripts/stylegan/training/train.py
    ```
    The script uses `pyrallis` for configuration, defined in the `TrainConfig` dataclass within the script. You can override default parameters via command-line arguments if needed (e.g., `python scripts/stylegan/training/train.py --num_iter 1000`). Refer to the `TrainConfig` class for available options.
